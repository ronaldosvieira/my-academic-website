<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ronaldo e Silva Vieira | publications</title>
    <meta name="author" content="Ronaldo e Silva Vieira" />
    <meta name="description" content="My publications so far, in reversed chronological order." />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®üèª‚Äçüíª</text></svg>">
    <link rel="stylesheet" href="/~ronaldo.vieira/assets/css/main.css">
    <link rel="canonical" href="https://homepages.dcc.ufmg.br//~ronaldo.vieira/publications/">

    <!-- Dark Mode -->
    <script src="/~ronaldo.vieira/assets/js/theme.js"></script>
    <script src="/~ronaldo.vieira/assets/js/dark_mode.js"></script>
  </head>

  <!-- Body -->
  <body class="sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm sticky-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://homepages.dcc.ufmg.br//~ronaldo.vieira/">Ronaldo e Silva  Vieira</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/~ronaldo.vieira/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/~ronaldo.vieira/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/~ronaldo.vieira/publications/">publications<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">My publications so far, in reversed chronological order.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">SBGames</abbr></div-->

        <!-- Entry bib key -->
        <div id="lemos2023" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Scale-invariant reinforcement learning in real-time strategy games</div>
          <!-- Author -->
          <div class="author">Lemos, Marcelo Luiz Harry Diniz,¬†
                  <em>Vieira, Ronaldo</em>,¬†Tavares, Anderson Rocha,¬†Marcolino, Leandro Soriano,¬†and Chaimowicz, Luiz
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 22th Brazilian Symposium on Computer Games and Digital Entertainment, SBGames 2023, Rio Grande, Brazil</em> 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/~ronaldo.vieira/assets/pdf/sbgames-2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Real-time strategy games present a significant challenge for artificial game-playing agents by combining several fundamental AI problems. Despite the difficulties, attempts to create autonomous agents using Deep Reinforcement Learning have been successful, with bots like AlphaStar beating even expert human players. Many RTS games include several distinct world maps with different dimensions, which may affect the agent‚Äôs observation and the representation of game states. However, most current architectures suffer from fixed input sizes or require extensive and complex training. In this paper, we overcome these limitations by combining Grid-Wise Control with Spatial Pyramid Pooling (SPP). Specifically, we employ the encoder-decoder framework provided by the GridNet architecture and enhance the critic component of PPO by adding an SPP layer to it. The new layer generates a standardized representation of any game state regardless of the initial observation dimensions, allowing the agent to act on any map. Our evaluation demonstrates that our proposed method improves the models‚Äô flexibility and provides a more effective and efficient solution for training autonomous agents in multiple RTS game scenarios.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">SBGames</abbr></div-->

        <!-- Entry bib key -->
        <div id="vieira2022b" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploring reinforcement learning approaches for battling in collectible card games</div>
          <!-- Author -->
          <div class="author">
                  <em>Vieira, Ronaldo</em>,¬†Tavares, Anderson Rocha,¬†and Chaimowicz, Luiz
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 21th Brazilian Symposium on Computer Games and Digital Entertainment, SBGames 2022, Natal, Brazil</em> 2022
          </div>
            <b>ü•â 3rd best paper award!</b>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/~ronaldo.vieira/assets/pdf/sbgames-2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Collectible card games (CCGs), such as Magic: the Gathering and Hearthstone, are a challenging domain where game-playing AI arguably has not yet reached human-level performance. We propose a deep reinforcement learning approach to battling in CCGs, using Legends of Code and Magic, a CCG designed for AI research, as a testbed. To do so, we formulate the battles as a Markov decision process, train agents to solve it, and evaluate them against two existing agents of different skill levels. Contrasting with the current state-of-the-art, our resulting agents act fast and can play many battles per second, despite their limited performance. We identify limitations and discuss several promising directions for improvement.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"></div-->

        <!-- Entry bib key -->
        <div id="vieira2022a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploring reinforcement learning approaches for drafting in collectible card games</div>
          <!-- Author -->
          <div class="author">
                  <em>Vieira, Ronaldo</em>,¬†Rocha Tavares, Anderson,¬†and Chaimowicz, Luiz
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Entertainment Computing</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1016/j.entcom.2022.100526" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Collectible card games (CCGs), such as Magic: the Gathering and Hearthstone, are played by tens of millions worldwide and are known for their usually large and intricate rules. From an artificial intelligence (AI) standpoint, playing CCGs consists of two interdependent tasks: deck-building and battling. This paper presents three deep reinforcement learning approaches for deck-building in the arena mode of CCGs. Our approaches are trained in self-play and differ in the handling of past information when drafting new cards for a deck. We formulate the problem in a game-agnostic manner and perform experiments on Legends of Code and Magic, a CCG designed for AI research. Considering the win rate of the decks when used by fixed battling agents, the results show that our trained drafting agents outperform the best ones available for the game and do so by building very different decks. We also reenact the Strategy Card Game AI competition and show that our best drafting strategy improves the win rate of a baseline competitor by 14.9 and 12.7 percentage points in the 2019 and 2020 editions.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">SBGames</abbr></div-->

        <!-- Entry bib key -->
        <div id="vieira2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Drafting in Collectible Card Games via Reinforcement Learning</div>
          <!-- Author -->
          <div class="author">
                  <em>Vieira, Ronaldo</em>,¬†Tavares, Anderson Rocha,¬†and Chaimowicz, Luiz
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 19th Brazilian Symposium on Computer Games and Digital Entertainment,
               SBGames 2020, Recife, Brazil</em> 2020
          </div>
            <b>ü•á Best paper award!</b>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/~ronaldo.vieira/assets/pdf/sbgames-2020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://www.youtube.com/watch?v=br-uwaXmKCA" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Collectible card games are played by tens of millions of players worldwide. Their intricate rules and diverse cards make them much more complex than traditional card games. To win, players must be proficient in two interdependent tasks: deck building and battling. In this paper, we present a deep reinforcement learning approach for deck building in arena mode - an understudied game mode present in many collectible card games, in which players build decks immediately before battling by drafting one card at a time from randomly presented candidates. We investigate three variants of the approach, and perform experiments on Legends of Code and Magic, a collectible card game designed for AI research. Results show that our learned draft strategies outperform those of the best agents of the game. Moreover, a participant of the Strategy Card Game AI competition improves from tenth to fourth place when coupled with our best drafting approach.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">Master thesis</abbr></div-->

        <!-- Entry bib key -->
        <div id="master-thesis" class="col-sm-8">
        <span id="master-thesis">Vieira, R. (2020). <i>Drafting in Collectible Card Games via Reinforcement Learning</i> [Thesis]. Departamento de Ci√™ncia da Computa√ß√£o, Universidade Federal de Minas Gerais.</span>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://repositorio.ufmg.br/handle/1843/38313" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/~ronaldo.vieira/assets/pdf/master-thesis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="https://www.youtube.com/watch?v=OItezchRzhI" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Video</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Collectible card games (CCGs), such as Magic: the Gathering and Hearthstone, are played by tens of millions of players worldwide, and their vast state and action spaces, intricate rules and diverse cards make them challenging for humans and artificial intelligence (AI) agents alike. In them, players build a deck using cards that representcreatures, items or spells from a fantasy world and use it to battle other players. Therefore, to win, players must be proficient in two interdependent tasks: deck building and battling. The advent of strong and fast AI players would enable, for instance, thorough playtesting of new cards before they are made available to the public, which is a longstanding problem in the CCG industry. In this thesis, we present a deep reinforcement learning approach for deck-building in the arena mode ‚Äì an understudied game mode present in most commercial collectible card games. In arena, players build decks immediately before battling by drafting one card at a time from randomly presented candidates. We formulate the problem in a game-agnostic manner and investigate three approaches that differ on how to consider the cards drafted so far in the next choices, using different game state representations and types of neural networks. We perform experiments on Legends of Code and Magic, a collectible card game designed for AI research. Considering the win rate of the decks when used by fixed battling AIs, the results show that our trained draft agents outperform the best draft agents of the game, and do so by building very different decks. Moreover, a participant of the Strategy Card Game AIcompetition improves from tenth to fourth place when using our best draft agent to build decks. We conclude with a discussion on the results, contributions and limitations of this work as well as directions for future research.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">SBGames</abbr></div-->

        <!-- Entry bib key -->
        <div id="vieira2019b" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Reinforcement Learning in Collectible Card Games: Preliminary Results on Legends of Code and Magic</div>
          <!-- Author -->
          <div class="author">
                  <em>Vieira, Ronaldo</em>,¬†Chaimowicz, Luiz,¬†and Tavares, Anderson Rocha
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In 18th Brazilian Symposium on Computer Games and Digital Entertainment,
               SBGames 2019, Rio de Janeiro, Brazil</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="/~ronaldo.vieira/assets/pdf/sbgames-2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
            <a href="/~ronaldo.vieira/assets/pdf/sbgames-2019-poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Games have long been a popular application area for research on artificial intelligence. They provide hard and diverse challenges whose solution often apply to real-life problems. Games like Chess, Go and recently Poker can be played by computers at superhuman level, but this performance is yet to be achieved in more complex games, such as collectible card games. To tackle this problem, we propose a pure reinforcement learning approach to the card game Legends of Code and Magic, in contrast to search strategies, most commonly used in this domain. In this paper, we present the intended methodology, preliminary results and the next steps of the project.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">Singular ETG</abbr></div-->

        <!-- Entry bib key -->
        <div id="vieira2019a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Modelando um esconde-esconde no Minecraft utilizando Hidden Markov Model</div>
          <!-- Author -->
          <div class="author">
                  <em>Vieira, Ronaldo</em>,¬†Leal, Matheus Rodrigues,¬†and Chaimowicz, Luiz
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Singular Engenharia, Tecnologia e Gest√£o</em> 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.33911/singular-etg.v1i1.16" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/~ronaldo.vieira/assets/pdf/singularetg-2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A cria√ß√£o de agentes inteligentes √© uma √°rea da intelig√™ncia artificial que busca construir entidades capazes de desempenhar a√ß√µes semelhantes aos seres humanos. Dessa forma, √© poss√≠vel modelar cen√°rios e avaliar a tomada de decis√£o de entidades envolvidas nesses cen√°rios. Este trabalho consiste na constru√ß√£o de agentes inteligentes para participarem da brincadeira de esconde-esconde. Para isso, √© desenvolvida uma abordagem probabil√≠stica baseada em um Hidden Markov Model, que utiliza o jogo Minecraft como plataforma para sua aplica√ß√£o. Os experimentos realizados demonstram que a estrat√©gia desenvolvida permite a intera√ß√£o entre os agentes de forma adequada √†s regras da brincadeira.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <!--div class="col-sm-2 abbr"><abbr class="badge">ICCSA</abbr></div-->

        <!-- Entry bib key -->
        <div id="DBLP:conf/iccsa/VieiraDAB18" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Cognitive Architecture for Agent-Based Artificial Life Simulation</div>
          <!-- Author -->
          <div class="author">
                  <em>Vieira, Ronaldo</em>,¬†Dembogurski, Bruno,¬†Alvim, Leandro G. M.,¬†and Braida, Filipe
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Computational Science and Its Applications - ICCSA 2018 - 18th International
               Conference, Melbourne, VIC, Australia, Proceedings,
               Part I</em> 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-95162-1_14" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/~ronaldo.vieira/assets/pdf/iccsa-2018.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The ability to simulate living beings that behave in a credible way is a fundamental aspect in digital games. This is due to its interdisciplinary characteristic, that brings together different fields of knowledge to better understand biological life and its processes. In this context, the design of an intelligent agent is a hard task as it involves a complex system, which has several interconnected components. In this work a virtual mind architecture for intelligent agents is proposed, where it simulates the cognitive processes of an actual brain, in this case attention and memory, in order to reproduce behaviors similar to those of actual living beings. A prototype is then proposed, where the architecture is applied on agents that represent virtual animals in a semantic-modeled ecosystem, and conduct a proof-of-concept experiment with it to demonstrate its effectiveness. In this experiment, the behavior of the virtual animals were consistent with reality, thus, validating the architecture‚Äôs ability to simulate living beings.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        ¬© Copyright 2023 Ronaldo e Silva Vieira. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
Last updated: December 13, 2023.
      </div>
    </footer>

    <div style="display: none;"><a href="https://clustrmaps.com/site/1bmb9" title="Visit tracker" target="_blank" rel="noopener noreferrer"><img src="//clustrmaps.com/map_v2.png?cl=080808&amp;w=800&amp;t=tt&amp;d=d_spdjlWR0R9Ld82tx8r4asX2-pE0FEPvZ4T4GzH6F8&amp;co=ffffff&amp;ct=808080"></a></div>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Mansory & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/~ronaldo.vieira/assets/js/mansory.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/~ronaldo.vieira/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/~ronaldo.vieira/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

